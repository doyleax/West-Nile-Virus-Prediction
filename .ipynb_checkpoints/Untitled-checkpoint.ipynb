{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# pip install pandas-profiling\n",
    "import pandas_profiling as pdp\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# this csv has all of the weather data, no scaling\n",
    "traps = pd.read_csv('assets/Train_transformed/traps_jd.csv')\n",
    "# traps = pd.read_csv('assets/train.csv')\n",
    "test = pd.read_csv('assets/Test_transformed/test_transformed_jd.csv')\n",
    "weather = pd.read_csv('assets/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test.to_csv('./assets/Test_transformed/test_transformed_jd.csv',sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traps.to_csv('/Users/jennydoyle/Desktop/dsi/West-Nile-Virus-Prediction/assets/Train_transformed/train_transformed_jd.csv',sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def weather_add(df, weather_col, func, days_range=7):\n",
    "    new_list = []\n",
    "    for i in df['Date']:\n",
    "        mask = (weather['Date'] <= i) & (weather['Date'] >= i - pd.Timedelta(days=days_range))\n",
    "        data_list = func(weather[weather_col][mask])\n",
    "        new_list.append(data_list)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## There isn't a column in test for NumMosquitos,\n",
    "## so we should get rid of it\n",
    "traps.drop('NumMosquitos',axis=1,inplace=True)\n",
    "\n",
    "## There were dupes in trap, and we didn't get rid\n",
    "## of them because it was possible that there were\n",
    "## tons of mosquitos from a single observation\n",
    "## and by practice, get separated into multiple rows\n",
    "## capped at 50\n",
    "## long story short -- let's DROP DUPES\n",
    "\n",
    "traps.drop_duplicates(inplace=True)\n",
    "test.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Trap', u'Latitude', u'Longitude', u'Date', u'WnvPresent',\n",
       "       u'NumMosquitos', u'Species_CULEX ERRATICUS', u'Species_CULEX PIPIENS',\n",
       "       u'Species_CULEX PIPIENS/RESTUANS', u'Species_CULEX RESTUANS',\n",
       "       u'Species_CULEX SALINARIUS', u'Species_CULEX TARSALIS',\n",
       "       u'Species_CULEX TERRITANS', u'year', u'month', u'day', u'Tmax', u'Tmin',\n",
       "       u'rain', u'Tmax_3', u'Tmax_20', u'Dew', u'Tmin_3', u'Tmin_20', u'Tavg',\n",
       "       u'WetBulb', u'CodeSum', u'StnPressure', u'SeaLevel', u'ResultSpeed',\n",
       "       u'ResultDir', u'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "features = traps.columns.drop(['Date','Trap','WnvPresent'])\n",
    "\n",
    "\n",
    "\n",
    "X = traps[features]\n",
    "y = traps.WnvPresent\n",
    "test_X = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=.7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def score_model(model,X_test):\n",
    "    preds = [x[1] for x in model.predict_proba(X_test)]\n",
    "    roc_score = roc_auc_score(y_test, preds)\n",
    "    return roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Gridsearch parameters for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AvgSpeed': 7,\n",
       " 'CodeSum': 7,\n",
       " 'Dew': 24,\n",
       " 'Latitude': 28,\n",
       " 'Longitude': 36,\n",
       " 'ResultDir': 8,\n",
       " 'ResultSpeed': 7,\n",
       " 'SeaLevel': 9,\n",
       " 'Species_CULEX PIPIENS': 4,\n",
       " 'Species_CULEX PIPIENS/RESTUANS': 3,\n",
       " 'Species_CULEX RESTUANS': 7,\n",
       " 'StnPressure': 11,\n",
       " 'Tavg': 2,\n",
       " 'Tmax': 4,\n",
       " 'Tmax_20': 3,\n",
       " 'Tmax_3': 4,\n",
       " 'Tmin': 5,\n",
       " 'Tmin_20': 17,\n",
       " 'Tmin_3': 2,\n",
       " 'WetBulb': 15,\n",
       " 'day': 1,\n",
       " 'month': 19,\n",
       " 'rain': 5,\n",
       " 'year': 20}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {}\n",
    "\n",
    "sum_wneg = len(traps[traps['WnvPresent']==0])\n",
    "sum_wpos = len(traps[traps['WnvPresent']==1])\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'binary:logitraw'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum_wneg/sum_wpos\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 3\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 1\n",
    "param['min_child_weight'] = 100\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 4\n",
    "\n",
    "num_round = 50\n",
    "\n",
    "#xgb.cv(param, dtrain, num_round, nfold=5)\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "bst.get_fscore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_feat_importances(model,X_train):\n",
    "    print \"Features sorted by their score:\"\n",
    "    feats = pd.DataFrame(sorted(zip(map(lambda x: round(x, 4), model.feature_importances_),X_train.columns), \n",
    "                 reverse=True))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75180840460516485"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators = 500, bootstrap=True, max_depth=None,\n",
    "                            max_features='auto',min_samples_leaf= 1, min_samples_split= 2)\n",
    "RF_model= RF.fit(X_train, y_train)\n",
    "score_model(RF_model,X_test)\n",
    "#0.74852283782251361 with new _20 columns\n",
    "#0.77771096561643926 without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  ['Latitude', 'Longitude', 'Species_CULEX ERRATICUS',\n",
    "#        'Species_CULEX PIPIENS', 'Species_CULEX PIPIENS/RESTUANS',\n",
    "#        'Species_CULEX RESTUANS', 'Species_CULEX SALINARIUS',\n",
    "#        'Species_CULEX TARSALIS', 'Species_CULEX TERRITANS', 'year',\n",
    "#        'month', 'day', 'Tmax', 'Tmin', 'rain', 'Tmax_3', 'Tmax_20',\n",
    "#        'Dew', 'Tmin_3', 'Tmin_20', 'Tavg', 'WetBulb', 'CodeSum',\n",
    "#        'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n",
    "\n",
    "\n",
    "# scale_feats = ['Latitude', 'Longitude','year','month', 'day', 'Tmax', 'Tmin', 'rain', 'Tmax_3', 'Tmax_20',\n",
    "#        'Dew', 'Tmin_3', 'Tmin_20', 'Tavg', 'WetBulb', 'CodeSum',\n",
    "#        'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n",
    "\n",
    "\n",
    "scale_feats = ['year','month', 'day', 'Tmax', 'Tmin', 'rain', 'Tmax_3', 'Tmax_20',\n",
    "       'Dew', 'Tmin_3', 'Tmin_20', 'Tavg', 'WetBulb',\n",
    "       'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, normalize\n",
    "\n",
    "\n",
    "## take out dummies\n",
    "X_modified = X[X.columns.drop(scale_feats)]\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X[scale_feats],y,train_size=.7, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_norm = pd.DataFrame(normalize(X[scale_feats],norm='l2'),columns=scale_feats)\n",
    "X_norm = X_modified.merge(X_norm,left_on=X_modified.index.values, right_on=X_norm.index.values)\n",
    "X_norm.drop('key_0',inplace=True,axis=1)\n",
    "\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm,y,train_size=.7, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "X_mm = pd.DataFrame(MinMaxScaler().fit_transform(X[scale_feats]),columns=scale_feats)\n",
    "X_mm = X_modified.merge(X_norm,left_on=X_modified.index.values, right_on=X_norm.index.values)\n",
    "X_mm.drop('key_0',inplace=True,axis=1)\n",
    "\n",
    "X_train_mm, X_test_mm, y_train_mm, y_test_mm = train_test_split(X_norm,y,train_size=.7, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "X_s = pd.DataFrame(StandardScaler().fit_transform(X[scale_feats]),columns=scale_feats)\n",
    "X_s = X_modified.merge(X_norm,left_on=X_modified.index.values, right_on=X_norm.index.values)\n",
    "X_s.drop('key_0',inplace=True,axis=1)\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_norm,y,train_size=.7, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_r = pd.DataFrame(RobustScaler().fit_transform(X[scale_feats]),columns=scale_feats)\n",
    "X_r = X_modified.merge(X_norm,left_on=X_modified.index.values, right_on=X_norm.index.values)\n",
    "X_r.drop('key_0',inplace=True,axis=1)\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_norm,y,train_size=.7, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params = { 'C' : [1,2,3.01,.001],\n",
    "                    'kernel':['rbf', 'linear','poly']\n",
    "}\n",
    "svmc= SVC(probability=True)\n",
    "gsvm = GridSearchCV(svmc, grid_search_params, scoring = 'roc_auc')\n",
    "k = gsvm.fit(X,y)\n",
    "k.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496165346671\n"
     ]
    }
   ],
   "source": [
    "svm_lin = SVC(kernel='linear',probability=True)\n",
    "svm_lin = svm_lin.fit(X_train,y_train)\n",
    "print score_model(svm_lin,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "# C : Inverse of regularization strength; must be a positive float, smaller values specify stronger regularization.\n",
    "model = SVC(kernel='linear',probability=True)\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(model, param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train,y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "score_model(grid,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54089948732\n",
      "0.54089948732\n",
      "0.544316357408\n",
      "0.535193761899\n",
      "0.45910051268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def svmc_model(X_train,y_train,X_test,y_test):\n",
    "    svmc= SVC(probability=True)\n",
    "    svm_s = svmc.fit(X_train,y_train)\n",
    "    print score_model(svm_s,X_test)\n",
    "    \n",
    "svmc_model(X_train,y_train,X_test,y_test)\n",
    "svmc_model(X_train_norm,y_train_norm,X_test_norm,y_test_norm)\n",
    "svmc_model(X_train_mm,y_train_mm,X_test_mm,y_test_mm)\n",
    "svmc_model(X_train_r,y_train_r,X_test_r,y_test_r)\n",
    "svmc_model(X_train_s,y_train_s,X_test_s,y_test_s)\n",
    "\n",
    "# 0.492821588651\n",
    "# 0.506074269924\n",
    "# 0.489718055995\n",
    "# 0.501245889311\n",
    "# 0.492224755448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##gradient boost, logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc-auc score: 0.498512393241\n",
      "\n",
      "Roc-auc score: 0.460744788154\n",
      "\n",
      "Roc-auc score: 0.508695859768\n",
      "\n",
      "Roc-auc score: 0.364008570525\n",
      "\n",
      "Roc-auc score: 0.421285160936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "def log(X,y,X_test,y_test):\n",
    "    # flatten y into a 1-D array\n",
    "    y_log = np.ravel(y)\n",
    "    model = LogisticRegression()\n",
    "    model = model.fit(X, y)\n",
    "    predicted = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "#     print 'CV scores: ' + str(scores)\n",
    "#     print 'CV score mean: ' + str(scores.mean())\n",
    "#     print 'Accuracy score: ' + str(metrics.accuracy_score(y_test, predicted))\n",
    "    print 'Roc-auc score: ' + str(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "    print ''\n",
    "    #     print 'Confusion matrix: ' + str(metrics.confusion_matrix(y_test, predicted))\n",
    "#     print 'Classification report: ' + str(metrics.classification_report(y_test, predicted))\n",
    "#     # check the accuracy on the training set\n",
    "#     print 'Model score: ' + str(model.score(X_test, y_test))\n",
    "#     print 'Kaggle: ' + str(score_model(model,X_test))\n",
    "\n",
    "\n",
    "\n",
    "log(X_train,y_train,X_test,y_test)\n",
    "log(X_train_norm,y_train_norm,X_test_norm,y_test_norm)\n",
    "log(X_train_s,y_train_s,X_test_s,y_test_s)\n",
    "log(X_train_r,y_train_r,X_test_r,y_test_r)\n",
    "log(X_train_mm,y_train_mm,X_test_mm,y_test_mm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858968314125\n",
      "\n",
      "0.515426646215\n",
      "\n",
      "0.539901283788\n",
      "\n",
      "0.495032855668\n",
      "\n",
      "0.508081121569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GradBoostClass(X_train,y_train,X_test,y_test):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "    clf.score(X_test, y_test)   \n",
    "    print score_model(clf,X_test)\n",
    "    print ''\n",
    "\n",
    "GradBoostClass(X_train,y_train,X_test,y_test)\n",
    "GradBoostClass(X_train_norm,y_train_norm,X_test_norm,y_test_norm)\n",
    "GradBoostClass(X_train_s,y_train_s,X_test_s,y_test_s)\n",
    "GradBoostClass(X_train_r,y_train_r,X_test_r,y_test_r)\n",
    "GradBoostClass(X_train_mm,y_train_mm,X_test_mm,y_test_mm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test) \n",
    "score_model(clf,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49179354345840975"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model_norm_l2= RF.fit(X_train_norm, y_train_norm)\n",
    "score_model(RF_model_norm_l2,X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48288580790326524"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model_mm = RF.fit(X_train_mm, y_train_mm)\n",
    "score_model(RF_model_mm,X_test_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5340717154776754"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model_s= RF.fit(X_train_s, y_train_s)\n",
    "score_model(RF_model_s,X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51396589695077921"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model_r= RF.fit(X_train_r, y_train_r)\n",
    "score_model(RF_model_r,X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. RandomForest Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params = { 'max_features' : ['auto',None],\n",
    "                    'max_depth':[None, 1, 5, 3],\n",
    "                    'min_samples_split':[2,3,5],\n",
    "                    'min_samples_leaf':[1,2,5],\n",
    "                    'bootstrap':[True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(RF, grid_search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-4f63dee943e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf_gs_grid = list(rf_gs.best_params_\n",
    "\n",
    "# rf_final = rf_gs_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3701</td>\n",
       "      <td>Longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3496</td>\n",
       "      <td>Latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>Species_CULEX PIPIENS/RESTUANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>Species_CULEX PIPIENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0246</td>\n",
       "      <td>Species_CULEX RESTUANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0141</td>\n",
       "      <td>Dew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>SeaLevel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0129</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0121</td>\n",
       "      <td>Tmin_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>StnPressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>WetBulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>Tmax_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>CodeSum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0093</td>\n",
       "      <td>Tavg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0091</td>\n",
       "      <td>Tmin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>ResultSpeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0078</td>\n",
       "      <td>AvgSpeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>Tmax_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>Tmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0074</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>ResultDir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0068</td>\n",
       "      <td>Tmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0029</td>\n",
       "      <td>Species_CULEX TERRITANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>Species_CULEX SALINARIUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>Species_CULEX ERRATICUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Species_CULEX TARSALIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                               1\n",
       "0   0.3701                       Longitude\n",
       "1   0.3496                        Latitude\n",
       "2   0.0362  Species_CULEX PIPIENS/RESTUANS\n",
       "3   0.0340           Species_CULEX PIPIENS\n",
       "4   0.0246          Species_CULEX RESTUANS\n",
       "5   0.0141                             Dew\n",
       "6   0.0132                        SeaLevel\n",
       "7   0.0129                           month\n",
       "8   0.0121                         Tmin_20\n",
       "9   0.0113                     StnPressure\n",
       "10  0.0109                         WetBulb\n",
       "11  0.0100                         Tmax_20\n",
       "12  0.0099                         CodeSum\n",
       "13  0.0093                            Tavg\n",
       "14  0.0091                          Tmin_3\n",
       "15  0.0089                     ResultSpeed\n",
       "16  0.0080                            rain\n",
       "17  0.0078                        AvgSpeed\n",
       "18  0.0076                          Tmax_3\n",
       "19  0.0075                            Tmax\n",
       "20  0.0074                            year\n",
       "21  0.0072                             day\n",
       "22  0.0070                       ResultDir\n",
       "23  0.0068                            Tmin\n",
       "24  0.0029         Species_CULEX TERRITANS\n",
       "25  0.0010        Species_CULEX SALINARIUS\n",
       "26  0.0006         Species_CULEX ERRATICUS\n",
       "27  0.0000          Species_CULEX TARSALIS"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84704358672881697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "xgm = model.fit(X_train, y_train, eval_metric=roc_auc_score)\n",
    "score_model(xgm,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51430161562748056"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "xgm = model.fit(X_train_norm, y_train_norm, eval_metric=roc_auc_score)\n",
    "score_model(xgm,X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51564449033428628"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "xgm = model.fit(X_train_s, y_train_s, eval_metric=roc_auc_score)\n",
    "score_model(xgm,X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9491\n",
      "AUC Score (Train): 0.939110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11bbcee50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAH7CAYAAAA3nh0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfGUyTA0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bcd1650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## credit : https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "\n",
    "#Choose all predictors except target & IDcols\n",
    "# predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "target = y_train\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "alg = xgb1\n",
    "dtrain = X_train\n",
    "predictors = features\n",
    "target = y_train\n",
    "useTrainCV=True\n",
    "cv_folds=5\n",
    "early_stopping_rounds=50\n",
    "\n",
    "xgb_param = alg.get_xgb_params()\n",
    "xgtrain = xgb.DMatrix(dtrain[predictors].values, label=target.values)\n",
    "cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "#Fit the algorithm on the data\n",
    "xbg_tuned = alg.fit(dtrain[predictors], target,eval_metric='auc')\n",
    "\n",
    "#Predict training set:\n",
    "dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "#Print model report:\n",
    "print \"\\nModel Report\"\n",
    "print \"Accuracy : %.4g\" % metrics.accuracy_score(target.values, dtrain_predictions)\n",
    "print \"AUC Score (Train): %f\" % metrics.roc_auc_score(target, dtrain_predprob)\n",
    "                    \n",
    "feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400830194985407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(xgb1,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.94690559150489462, {'n_estimators': 10, 'learning_rate': 0.1})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_param_grid = {'n_estimators': [10, 30, 100, 300, 1000],\n",
    "                  'learning_rate': [0.1, 0.3, 1.0, 3.0]}\n",
    "\n",
    "\n",
    "ada_est = AdaBoostClassifier()\n",
    "ada_gs_cv = GridSearchCV(ada_est, ada_param_grid).fit(X_train, y_train)\n",
    "print(ada_gs_cv.best_score_, ada_gs_cv.best_params_)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76036102440450981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(ada_gs_cv,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81477579960728375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(learning_rate=0.1,n_estimators=10000,algorithm='SAMME')\n",
    "ada_model=adaboost.fit(X_train,y_train)\n",
    "score_model(ada_model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666228491623446"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "ada_model_basic = adaboost.fit(X_train,y_train)\n",
    "score_model(ada_model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ada_model, xgm\n",
    "\n",
    "\n",
    "def ensemble_and_export(model1,model2,test_X, test_y,file_name):\n",
    "    pred_m1 = []\n",
    "    predictions_m1 =  model1.predict_proba(test_X)\n",
    "    pred_m2 = []\n",
    "    predictions_m2 =  model2.predict_proba(test_X)\n",
    "\n",
    "    for x in predictions_m1:\n",
    "        pred_m1.append(x[1])\n",
    "\n",
    "    for x in predictions_m2:\n",
    "        pred_m2.append(x[1])\n",
    "\n",
    "    indexes=np.arange(1, len(predictions_m1)+1, 1)\n",
    "\n",
    "    preds_m1 = pd.DataFrame(data=[indexes, pred_m1]).T\n",
    "    preds_m1.columns =['Id','WnvPresent']\n",
    "    preds_m1['Id'] = preds_m1.Id.astype(int)\n",
    "\n",
    "    preds_m2 = pd.DataFrame(data=[indexes, pred_m2]).T\n",
    "    preds_m2.columns =['Id','WnvPresent']\n",
    "    preds_m2['Id'] = preds_m2.Id.astype(int)\n",
    "    \n",
    "    ensemble = preds_m1.merge(preds_m2,left_on='Id', right_on='Id')\n",
    "    \n",
    "    ensemble['avg'] = (ensemble['WnvPresent_x']+ ensemble['WnvPresent_y']) / 2\n",
    "    ensemble.rename(columns={'avg':'WnvPresent'},inplace=True)\n",
    "\n",
    "    ensemble = ensemble[['Id','WnvPresent']]\n",
    "\n",
    "    location = './submissions/{}_{}.csv'.format(file_name, time.strftime(\"%d_%m_%Y\"))\n",
    "    ensemble.to_csv(location, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Transform Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('./assets/Test_transformed/test_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###This function will takes a model and a model name(as a string), generate predictions, \n",
    "### and save that as a CSV labeled with the model name and date.\n",
    "import time \n",
    "import math\n",
    "def model_and_export(model, model_name):\n",
    "    pred_list = []\n",
    "#     predictions = [\"%.1f\" % (math.ceil(x[1] * 100) / 100) for x in model.predict_proba(test_X)]\n",
    "    predictions =  model.predict_proba(test_X)\n",
    "    for x in predictions:\n",
    "        pred_list.append(x[1])\n",
    "    indexes=np.arange(1, len(predictions)+1, 1)\n",
    "    preds_df = pd.DataFrame(data=[indexes, pred_list]).T\n",
    "    preds_df.columns =['Id','WnvPresent']\n",
    "    preds_df['Id'] = preds_df.Id.astype(int)\n",
    "    location = './submissions/{}_{}.csv'.format(model_name, time.strftime(\"%d_%m_%Y\"))\n",
    "    preds_df.to_csv(location, index=False)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_and_export(ada_model, 'ADA_JD1')\n",
    "#Your submission scored 0.74416."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_and_export(xgm, 'XGB_JD1')\n",
    "#Your submission scored 0.71777."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_and_export(xgm, 'XGB_JD2')\n",
    "#Your submission scored 0.75110."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_and_export(xgb_tuned, 'XGB_JD3')\n",
    "#Your submission scored 0.74416."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_and_export(ada_model, 'ADA_JD2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_and_export(clf, 'GB_JD1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ada_gs_cv\n",
    "model_name = 'ADA_JD4'\n",
    "pred_list = []\n",
    "predictions =  model.predict_proba(test_X)\n",
    "for x in predictions:\n",
    "    pred_list.append(x[1])\n",
    "indexes=np.arange(1, len(predictions)+1, 1)\n",
    "preds_df = pd.DataFrame(data=[indexes, pred_list]).T\n",
    "preds_df.columns =['Id','WnvPresent']\n",
    "preds_df['Id'] = preds_df.Id.astype(int)\n",
    "location = './submissions/{}_{}.csv'.format(model_name, time.strftime(\"%d_%m_%Y\"))\n",
    "preds_df.to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.003993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.001650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116263</th>\n",
       "      <td>116264.0</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116264</th>\n",
       "      <td>116265.0</td>\n",
       "      <td>0.010551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116265</th>\n",
       "      <td>116266.0</td>\n",
       "      <td>0.006137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116266</th>\n",
       "      <td>116267.0</td>\n",
       "      <td>0.012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116267</th>\n",
       "      <td>116268.0</td>\n",
       "      <td>0.012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116268</th>\n",
       "      <td>116269.0</td>\n",
       "      <td>0.012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116269</th>\n",
       "      <td>116270.0</td>\n",
       "      <td>0.052899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116270</th>\n",
       "      <td>116271.0</td>\n",
       "      <td>0.027128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116271</th>\n",
       "      <td>116272.0</td>\n",
       "      <td>0.050605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116272</th>\n",
       "      <td>116273.0</td>\n",
       "      <td>0.030124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116273</th>\n",
       "      <td>116274.0</td>\n",
       "      <td>0.015866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116274</th>\n",
       "      <td>116275.0</td>\n",
       "      <td>0.036685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116275</th>\n",
       "      <td>116276.0</td>\n",
       "      <td>0.036685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116276</th>\n",
       "      <td>116277.0</td>\n",
       "      <td>0.036685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116277</th>\n",
       "      <td>116278.0</td>\n",
       "      <td>0.012180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116278</th>\n",
       "      <td>116279.0</td>\n",
       "      <td>0.011390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116279</th>\n",
       "      <td>116280.0</td>\n",
       "      <td>0.013552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116280</th>\n",
       "      <td>116281.0</td>\n",
       "      <td>0.007971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116281</th>\n",
       "      <td>116282.0</td>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116282</th>\n",
       "      <td>116283.0</td>\n",
       "      <td>0.009720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116283</th>\n",
       "      <td>116284.0</td>\n",
       "      <td>0.009720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116284</th>\n",
       "      <td>116285.0</td>\n",
       "      <td>0.009720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116285</th>\n",
       "      <td>116286.0</td>\n",
       "      <td>0.018894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116286</th>\n",
       "      <td>116287.0</td>\n",
       "      <td>0.011439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116287</th>\n",
       "      <td>116288.0</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116288</th>\n",
       "      <td>116289.0</td>\n",
       "      <td>0.010032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116289</th>\n",
       "      <td>116290.0</td>\n",
       "      <td>0.004916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116290</th>\n",
       "      <td>116291.0</td>\n",
       "      <td>0.012272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116291</th>\n",
       "      <td>116292.0</td>\n",
       "      <td>0.012272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116292</th>\n",
       "      <td>116293.0</td>\n",
       "      <td>0.012272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "0            1.0  0.001972\n",
       "1            2.0  0.001370\n",
       "2            3.0  0.001439\n",
       "3            4.0  0.001199\n",
       "4            5.0  0.001129\n",
       "5            6.0  0.001422\n",
       "6            7.0  0.001422\n",
       "7            8.0  0.001422\n",
       "8            9.0  0.000790\n",
       "9           10.0  0.000839\n",
       "10          11.0  0.000897\n",
       "11          12.0  0.000690\n",
       "12          13.0  0.000709\n",
       "13          14.0  0.000758\n",
       "14          15.0  0.000758\n",
       "15          16.0  0.000758\n",
       "16          17.0  0.005172\n",
       "17          18.0  0.003993\n",
       "18          19.0  0.003997\n",
       "19          20.0  0.003374\n",
       "20          21.0  0.002631\n",
       "21          22.0  0.004000\n",
       "22          23.0  0.004000\n",
       "23          24.0  0.004000\n",
       "24          25.0  0.001689\n",
       "25          26.0  0.001816\n",
       "26          27.0  0.001713\n",
       "27          28.0  0.001391\n",
       "28          29.0  0.001018\n",
       "29          30.0  0.001650\n",
       "...          ...       ...\n",
       "116263  116264.0  0.017904\n",
       "116264  116265.0  0.010551\n",
       "116265  116266.0  0.006137\n",
       "116266  116267.0  0.012858\n",
       "116267  116268.0  0.012858\n",
       "116268  116269.0  0.012858\n",
       "116269  116270.0  0.052899\n",
       "116270  116271.0  0.027128\n",
       "116271  116272.0  0.050605\n",
       "116272  116273.0  0.030124\n",
       "116273  116274.0  0.015866\n",
       "116274  116275.0  0.036685\n",
       "116275  116276.0  0.036685\n",
       "116276  116277.0  0.036685\n",
       "116277  116278.0  0.012180\n",
       "116278  116279.0  0.011390\n",
       "116279  116280.0  0.013552\n",
       "116280  116281.0  0.007971\n",
       "116281  116282.0  0.004296\n",
       "116282  116283.0  0.009720\n",
       "116283  116284.0  0.009720\n",
       "116284  116285.0  0.009720\n",
       "116285  116286.0  0.018894\n",
       "116286  116287.0  0.011439\n",
       "116287  116288.0  0.017093\n",
       "116288  116289.0  0.010032\n",
       "116289  116290.0  0.004916\n",
       "116290  116291.0  0.012272\n",
       "116291  116292.0  0.012272\n",
       "116292  116293.0  0.012272\n",
       "\n",
       "[116293 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_hat[i]==1 and y_actual!=y_hat[i]:\n",
    "           FP += 1\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_hat[i]==0 and y_actual!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
